{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistically Comparing Values\n",
    "\n",
    "***\n",
    "## Quick Intro into Normal Distrubutions\n",
    "\n",
    "*Disclaimer:* Taylor does a much better job describing this in a lot of detail, and if you haven't read his section on comparing values, you should do so (Chapters 2.3-2.5 pp. 16-24).\n",
    "\n",
    "In real life, no matter how accurately you take a measurement, it is always subject to some amount of **random error**. <font color=#aa0000>It is very unusual if the two measurements you take are exactly the same.</font> There is nothing *bad* about the random error, but as scientists, we need to be aware it exists. \n",
    "\n",
    "The most common way to account for it is to say that *measurements are **normally** distributed*. In other words, they lie on a *Gaussian* or a *Bell* curve <font color=#cccccc>which you will become intimately familiar with during your career at JHU</font>.\n",
    "\n",
    "***\n",
    "\n",
    "For a second, imagine you're in a lab, measuring a diameter of a ball. I know (from asking the manufacturer), that the balls they make have a **true** average diameter\n",
    "\n",
    "$$\\textrm{D}_{\\textrm{Ball}}^{\\textrm{True}} = 20 \\textrm{cm} $$.\n",
    "\n",
    ">*Note:* if you've read the assignment, this *true* mean is the **population mean**. I.e. if I take the entire >population of balls, this is its mean diameter. \n",
    ">If you haven't read the assignment (\"Random Uncertainties\"), do that before reading further!\n",
    "\n",
    "\n",
    "Measuring a round object is difficult, as we have seen in Lab 0. I am measuring it with a ruler and I don't trust my estimation of diameter (or the ruler) very much, so I will assign an uncertainty of $\\pm 0.5$ cm. <br>\n",
    "If I measure the ball $100,000$ times and plot my measurements on a histogram, I will get slightly different answers. I can plot my measurements on a histogram, to see the distribution:\n",
    "\n",
    "<img src=\"../images/stats-normal.png\">\n",
    "\n",
    "You can see on the histogram that my measurements are **normally distributed**, i.e. form a beautiful curve shown in purple. <font color=#cccccc>If you don't believe me, try it yourself! Measure a ball $100,000$ times and you'll get your very own bell curve.</font> These kinds of distributions are characterized by two numbers:\n",
    "\n",
    "1. **Average**, our best estimate of the measured value\n",
    "2. **Standard Deviation** ($\\sigma$), or how much do my measurements *vary* <font color=#cccccc>(how off they generally are from the mean - reminds you of uncertainty, huh?)</font>\n",
    "\n",
    "If you know the mean and the standard deviation of your measurements, you can immediately say things like:\n",
    "\n",
    "- 68% of all measurements lie within $1\\sigma$ of the average, or in the range (19.5, 20.5) cm\n",
    "- 32% of all measurements lie **outside** the $1\\sigma$ of the average. <br>\n",
    "  So 32% of the times, something will go wrong and I will measure $D < 19.5$ cm or $D > 20.5$ cm\n",
    "- Measuring a completely wrong diameter is **unlikely** but **not impossible**. <br>\n",
    "\n",
    "For example, there is a 0.01% chance of measuring $D > 22$ cm or $D < 18$ cm. This seems like a small chance, but it also means that out of my $100,000$ measurements with uncertainty $0.5$ cm, 10 are expected to be off by 2 cm!\n",
    "\n",
    "Until now, we captured this \"variation\" idea using uncertainties. <br>\n",
    "When you measure the diameter to be $X \\pm \\delta X$, you are saying: \"I measured diameter $X$, but it can likely be anything from $X-\\delta X$ to $X + \\delta X$ because I'm uncertain\". <br>\n",
    "Ideally, **uncertainty should represent a 1$\\sigma$ range around the true mean**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty of the Mean\n",
    "***\n",
    "\n",
    "Well, we can see now that if you let me measure balls with rullers, I'd get vastly different diameters each time, because my uncertainty is huge <font color=#aaaaaa> and measuring round things is hard!</font> But when I measured the ball $10,000$ times and got a beautiful bell curve like the one above, isn't the **average**, or the **peak of the curve**, pretty well defined? \n",
    "\n",
    "#### Yes! \n",
    "Inf fact, that's why scientists always try to take as much data as possible. Taking more data *does not make me more confident in any single measurement*, since measuring balls doesn't get easier with time! But, every time, **I am more and more confident in my mean.**\n",
    "\n",
    "This effect even has a fancy statistic theorem, called **Central Limit Theorem**.\n",
    "\n",
    "> The **mean** of my sample ($10,000$ measurements) is also *normally distributed* and the **standard deviation** (aka uncertainty) **of the mean** is $\\bar{\\sigma} = \\sigma / \\sqrt{N}$ where $N$ is the sample size.\n",
    "\n",
    "So even though I am uncertain in each individual measurement, since my $\\sigma = 0.5$ cm, I am ***very*** certain that the average diameter of the ball I measured is:\n",
    "\n",
    "$$\\bar{D}_{avg} = \\Big( 20 \\pm \\frac{0.5}{\\sqrt{10,000}} \\Big) \\textrm{ cm } = 20.000 \\pm 0.005 \\textrm{ cm} $$\n",
    "\n",
    "Now, when you compare values and check if they are consistent, you need to be careful:\n",
    "\n",
    "- Are you comparing **average** values? In this case, use standard deviation of the mean!\n",
    "- Are you comparing two **individual measurement**? In this case, the uncertainty is just the regular standard deviation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing numbers using standard deviations\n",
    "***\n",
    "\n",
    "So, why does this matter? Well, in the end, we use uncertainties to see how our measurements compare to other people's. But, since we always assume the uncertainty is just 1 standard deviation, now we know that there's a **whopping 32% chance to measure something *outside* the uncertainty**. In other words, if I make exactly the same measurement 3 times, one of them is likely to fall outside of my uncertainty range!\n",
    "\n",
    "Remember, until now we've compared measurements by seeing if their error bars overlap. Is that fair? Well, not exactly.\n",
    "\n",
    "Let's go back to the example of measuring Hubble constant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hubble Constant Example\n",
    "\n",
    "Remember, we have two different measurements of the Hubble Constant: made by Adam Reiss and Chuck Benett <font color=#cccccc>who work in neighboring offices, isn't it insane??</font>, and these measurements are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0_reiss  = 73.52\n",
    "dH0_reiss = 1.62 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0_bennett  = 69.32\n",
    "dH0_bennett = 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between Reiss' and Bennet's H0 = 4.2 +/- 1.8 (km/s) / Mpc\n"
     ]
    }
   ],
   "source": [
    "diff  = abs( H0_reiss - H0_bennett )\n",
    "ddiff = pow( dH0_reiss**2 + dH0_bennett**2, 0.5 )\n",
    "print(\"Difference between Reiss' and Bennet's H0 = %2.1f +/- %2.1f (km/s) / Mpc\" % (diff, ddiff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, think of difference as a normally distributed measurement. In other words, if Adam Reiss and Chuck Bennett did $100,000$ experiments measuring **the same thing ($H_0$)** each, and then calculated their difference each time, what would the distribution of differences be? Since they're measuring the same thing, we would expect the mean difference of those $100,000$ trials to be 0.\n",
    "\n",
    "Using the new statistics language, we ask\n",
    " > Can our measurement of **Difference = 4.2** come randomly (by accident) from a distribution with **True Difference = 0** and **$\\sigma$=1.8**?\n",
    "\n",
    "<img src=\"../images/stats-difference.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From before, we know\n",
    "- The probability of measuring something **more than** $1\\sigma$ away (in either direction) from the mean is $32\\%$\n",
    "- The probability of measuring something **more than** $2\\sigma$ away is $5\\%$. \n",
    "\n",
    "How many sigmas away is our difference? *(We call this t-value)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-value = 2.32\n"
     ]
    }
   ],
   "source": [
    "t = diff / ddiff\n",
    "print(\"T-value = %2.2f\" % t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our difference is $2.3\\sigma$ away from the true mean, where $\\sigma = 1.8$ is our uncertainty. <br>\n",
    "Here is a rule of thumb to interpret this:\n",
    "\n",
    "#### Rule of thumb: t-values\n",
    "\n",
    "- If $t<1$, $0$ is within the uncertainty of the difference, or the error bars overlap. The measurements are consistent!\n",
    "- If $t>3$, the difference is more than 3 deviations away from 0. There is only a $0.3\\%$ chance the measurements are consistent. So we say they are not consistent.\n",
    "- If $1<t<3$, it's trickier. The error bars do not overlap, but the difference is not much greater than 0 (between 1 and 3 deviations). It is up to you, the experimenter, and me, the reader, to decide on our own if we think the two measurements are consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Better scientific statement: probabilities\n",
    "\n",
    "The probability of getting this t-value is given by the area under the curve (shaded in purple on the plot).   This is just the following equation:\n",
    "$$ 1 - \\frac{1}{\\sqrt{2\\pi}} \\int_{-t}^{t} e^{-z^2/2} dz.$$\n",
    "\n",
    "This is a commonly used integral.   Taylor provides a handy table that can be used to look-up the probability associated with a given value of $t$.   See Appendix A (pp. 286-287). \n",
    "\n",
    "Python also privides a way to quickly take this integral in `scipy.stats.norm`.   The integral above is called the \"survival function\" (sf for short).  \n",
    "\n",
    "Learn more about `scipy.stats.norm` here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability = 0.02009\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "probability = st.norm.sf(t)*2   #calculate the survival function.\n",
    "# sf is calculated from 0 to +infinity.   Multiply by 2 to get -infinity -- +infinity\n",
    "\n",
    "print(\"Probability = %2.5f\" % probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: in the olden days (when I was studying this), we had to look up *probability tables*. Taylor has one of these in Appendix A, Table A. Try using it a couple of times - it can be useful to get a rough idea of what do these probabilities really mean!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a 2% probability that the values are compatible. This is pretty low, but not **incredibly** low. In most studies, researchers often reject the idea that the measurements come from the same sample if $p < 0.05$ or $\\sigma < 1.96$, but in some areas of physics we often require stronger evidence.\n",
    "\n",
    "For example, the evidence for dark matter is now at $50\\sigma$. In other words, if we lived in dark matter-less world, the probability that we just happenned to randomly observe things we see is $10^{-350}$! That's a pretty strong evidence :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This is why all of the cosmologists are confused: there is still a *small but not negligible* chance the difference between two studies is due to random error, but there is also a chance there is some new physics we don't know about yet!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
